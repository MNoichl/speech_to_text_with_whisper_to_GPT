{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MNoichl/speech_to_text_with_whisper_to_GPT/blob/main/whisper_to_GPT_MN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actually useful speech to text via Whisper and GPT-4 üé§ ‚å® üòé\n",
        "\n",
        "This notebook provides a workflow to turn a dictation, which you can create e.g. with Audacity on your PC, into a reasonable piece of text of the genre that you need. After transcribing your text using the whisper model, the notebook passes it to GPT-4, with the instructions to fix any dictation infedilities, and to adapt it to your predefined style, usually without any typos.\n",
        "\n",
        "I use this for E-Mails, to-do-lists, drafting, meeting-minutes and also to turn ramblings into reasonable notes. You can also dictate several E-mails in a row. No need to worry to much about pauses as well. The GitHub-repo contains also a (hopefully growing) style-sheet, and a notebook that helps in the creation of styles.\n",
        "\n",
        "Importantly, for this to work, you will need an OpenAi-API-key, and pay for your usage. I feel this is quite reasonably priced, but until you get a feeliong for it, I suggest you monitor your spending! Also **make sure to double check your texts**. E.g. dictated last names in E-Mails are commonly mispelled, and might need post-hoc fixing. First, we need to install some stuff:"
      ],
      "metadata": {
        "id": "3NOGaGPEdsB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#@markdown #Load some dependencies!\n",
        "# !pip install gradio -q\n",
        "!pip install openai\n",
        "!pip install noisereduce\n",
        "!pip install pydub\n",
        "\n",
        "import time\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_nonsilent\n",
        "from scipy.io import wavfile\n",
        "import noisereduce as nr\n",
        "import openai\n",
        "\n",
        "import datetime"
      ],
      "metadata": {
        "id": "fjM27tWsI4dH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Set everything up\n",
        "\n",
        "#@markdown # Mount drive \n",
        "#@markdown Check this if you want to mount your drive. I would reccomend to do that, because this way,\n",
        "#@markdown you can save your recordings in a drive-folder on your PC, and load them from there,\n",
        "#@markdown without the hassle of individually uploading them everytime. Also you can (reasonably) savely store\n",
        "#@markdown your API-key.\n",
        "\n",
        "mount_drive = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if mount_drive:\n",
        "  # Mount Google Drive\n",
        "  drive.mount('/content/drive')\n",
        "#@markdown # Set up your API-key\n",
        "#@markdown Here you have to provide your api-key to the OpenAI-API. \n",
        "#@markdown **WARNING: Do not share the notebook with your key in it (or in it's edit-history),\n",
        "#@markdown because this will allow people to spend your money! \n",
        "#@markdown Also make sure to set reasonable spending limits at OpenAIs website,\n",
        "#@markdown and monitor your spending regularly.** Alternatively you can\n",
        "#@markdown  put a path to a text file in your drive, where you keep your key.\n",
        "\n",
        "api_key_or_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Check if api_key is a file\n",
        "if os.path.isfile(api_key_or_path):\n",
        "    # If it is a file, open it and read the content into a string\n",
        "    with open(api_key_or_path, 'r') as file:\n",
        "        api_key = file.read()\n",
        "    openai.api_key = api_key # this tells the OpenAI library about your key, so it can be used below.\n",
        "else:\n",
        "    openai.api_key = api_key_or_path # this tells the OpenAI library about your key, so it can be used below.\n",
        "\n",
        "\n",
        "#@markdown # Load your file:\n",
        "\n",
        "\n",
        "#@markdown Specify a directory or audio-file which you want to transcribe.\n",
        "#@markdown If a directory is specified, the most recently saved file is loaded.\n",
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/whisper_transcripts/recordings' #@param {type:\"string\"}\n",
        "\n",
        "# Check if the path is a directory or a file\n",
        "if os.path.isdir(path):\n",
        "    # If the path is a directory, change the current working directory to the specified path\n",
        "    os.chdir(path)\n",
        "\n",
        "    # List all files in the directory\n",
        "    files = os.listdir()\n",
        "\n",
        "    # Print the list of files\n",
        "    print(\"Files in directory:\", files)\n",
        "\n",
        "    # Find the latest file (i.e., the file with the most recent modification time)\n",
        "    latest_file = max(files, key=os.path.getmtime)\n",
        "    \n",
        "    # Print the time when the last added file was recorded\n",
        "    print(\"Last recorded file time:\", datetime.datetime.fromtimestamp(os.path.getmtime(latest_file)))\n",
        "    # date_time = mod_time)\n",
        "    # Specify the working directory\n",
        "    working_dir = '/content'\n",
        "\n",
        "    # Copy the latest file to the working directory and rename it as 'current_audio.mp3'\n",
        "    shutil.copy(os.path.join(path, latest_file), os.path.join(working_dir, 'current_audio.mp3'))\n",
        "    \n",
        "else:\n",
        "    # If the path is a file, copy it to the working directory and rename it as 'current_audio.mp3'\n",
        "    working_dir = '/content'\n",
        "    shutil.copy(path, os.path.join(working_dir, 'current_audio.mp3'))\n",
        "    \n",
        "    # Print the time when the file was last modified\n",
        "    print(\"Last recorded file time:\", datetime.datetime.fromtimestamp(os.path.getmtime(path)))\n",
        "    \n",
        "    # The latest file is the file itself\n",
        "    latest_file = path\n",
        "\n",
        "# Change the current working directory to the working directory\n",
        "os.chdir(working_dir)\n",
        "\n",
        "# Get the size of the 'current_audio.mp3' file\n",
        "file_size = os.path.getsize('current_audio.mp3')\n",
        "\n",
        "# Print the size of the file in megabytes\n",
        "print(\"File size in MB:\", file_size / (1024 * 1024))\n",
        "\n"
      ],
      "metadata": {
        "id": "ILFOYNnTcYe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd579cb8-efb8-498b-db1f-b81ed72443c4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Files in directory: ['rec0330-004051.mp3', 'rec0330-005353.mp3', 'rec0330-005533.mp3', 'rec0330-011500.mp3', 'rec0330-131940.mp3', 'rec0330-132315.mp3', 'rec0331-134231.mp3', 'rec0331-135136.mp3', 'rec0331-135257.mp3', 'rec0331-190408.mp3', 'rec0402-172127.mp3', 'rec0402-172137.mp3', 'rec0402-184648.mp3', 'rec0402-211045.mp3', 'rec0404-180034.mp3', 'rec0412-140902.mp3', 'rec0412-141024.mp3', 'rec0412-150105.mp3', 'rec0412-190837.mp3', 'rec0413-134437.mp3', 'rec0419-012022.mp3', 'rec0419-012807.mp3', 'rec0419-012854.mp3', 'rec0420-195205.mp3', 'rec0420-195239.mp3', 'rec0420-201028.mp3', 'rec0427-162614.mp3', 'rec0427-162647.mp3', 'rec0427-172429.mp3', 'rec0430-002737.mp3', 'rec0430-002753.mp3', 'rec0503-153105.mp3', 'rec0503-153123.mp3', 'rec0503-161853.mp3', 'rec0506-130227.mp3', 'rec0506-130617.mp3', 'rec0508-140714.mp3', 'rec0508-162059.mp3', 'rec0508-163756.mp3', 'rec0509-011617.mp3', 'rec0509-125545.mp3', 'rec0509-131506.mp3', 'rec0509-131827.mp3', 'unbenannt.mp3', 'unbenanasdfasdft.mp3', 'arbeitsplan_fresh.mp3', 'gareth_email_philmath_demot.mp3', 'emails_22_5.mp3', 'email_bryan.mp3', 'faissplan.mp3', 'hashchunk.mp3', 'mailgeorgcharles.mp3', 'pace_cover_latter.mp3', 'emails1623.mp3', 'emails1623_de.mp3', 'Gareth_testing.mp3']\n",
            "Last recorded file time: 2023-06-10 23:17:58\n",
            "File size in MB: 0.322723388671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def reduce_noise_in_directory(directory):\n",
        "    \"\"\"\n",
        "    This function reduces noise in all .mp3 files in a given directory.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.mp3'):\n",
        "            # Convert mp3 to wav\n",
        "            input_path = os.path.join(directory, filename)\n",
        "            wav_path = os.path.join(directory, f\"{os.path.splitext(filename)[0]}.wav\")\n",
        "            subprocess.run(f\"ffmpeg -y -i {input_path} {wav_path} -hide_banner -loglevel error\", shell=True)\n",
        "\n",
        "            # Load wav data and perform noise reduction\n",
        "            rate, data = wavfile.read(wav_path)\n",
        "            data = data[:,0]\n",
        "            reduced_noise = nr.reduce_noise(y=data, sr=rate,chunk_size=6000)\n",
        "\n",
        "            # Save reduced noise wav file\n",
        "            reduced_wav_path = os.path.join(directory, f\"{os.path.splitext(filename)[0]}_reduced_noise.wav\")\n",
        "            wavfile.write(reduced_wav_path, rate, reduced_noise)\n",
        "\n",
        "            # Convert reduced noise wav back to mp3\n",
        "            reduced_mp3_path = os.path.join(directory, f\"{os.path.splitext(filename)[0]}.mp3\")\n",
        "            subprocess.run(f\"ffmpeg -y -i {reduced_wav_path} {reduced_mp3_path} -hide_banner -loglevel error\", shell=True)\n",
        "\n",
        "            # Remove intermediate wav files\n",
        "            os.remove(wav_path)\n",
        "            os.remove(reduced_wav_path)\n",
        "\n",
        "\n",
        "def remove_long_silences(input_file, output_file, silence_length_ms=1000, silence_thresh=-50):\n",
        "    \"\"\"\n",
        "    This function removes long silences from an audio file.\n",
        "    It doesn't really work right now though.\n",
        "    \"\"\"\n",
        "    # Load audio file\n",
        "    audio = AudioSegment.from_file(input_file, format=os.path.splitext(input_file)[1][1:])\n",
        "\n",
        "    # Detect non-silent chunks\n",
        "    nonsilent_chunks = detect_nonsilent(audio, min_silence_len=silence_length_ms, silence_thresh=silence_thresh)\n",
        "\n",
        "    # Concatenate non-silent chunks\n",
        "    output_audio = AudioSegment.empty()\n",
        "    for start, end in nonsilent_chunks:\n",
        "        output_audio += audio[start:end]\n",
        "\n",
        "    # Export the audio file without longer silences\n",
        "    output_audio.export(output_file, format=os.path.splitext(output_file)[1][1:])\n",
        "\n",
        "\n",
        "def split_audio_file_into_chunks(input_file, output_folder='intermediate_chunks', chunk_length=30,reduce_noise=True):\n",
        "    \"\"\"\n",
        "    This function splits an audio file into chunks of a specified length.\n",
        "    \"\"\"\n",
        "    # Remove the output folder if it exists, and create a new one\n",
        "    !ffmpeg -y -i $input_file current_audio.wav -hide_banner -loglevel error\n",
        "\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    # Load the input audio file\n",
        "    audio = AudioSegment.from_file(\"current_audio.wav\")\n",
        "\n",
        "    # Calculate the chunk length in milliseconds\n",
        "    chunk_length_ms = chunk_length * 1000\n",
        "\n",
        "    # Split the audio into chunks and export them\n",
        "    if chunk_length_ms > len(audio):\n",
        "      output_filename = f\"{output_folder}/{str(0).zfill(4)}.mp3\"\n",
        "      audio.export(output_filename, format=\"mp3\")\n",
        "    else:\n",
        "      num_chunks = len(audio) // chunk_length_ms\n",
        "      remaining_duration = len(audio) % chunk_length_ms\n",
        "\n",
        "      for i in range(num_chunks):\n",
        "          start_time = i * chunk_length_ms\n",
        "          if i != num_chunks-1:\n",
        "            end_time =(i + 1) * chunk_length_ms\n",
        "          else:\n",
        "            end_time = len(audio)\n",
        "          chunk = audio[start_time:end_time]\n",
        "          output_filename = f\"{output_folder}/{str(i).zfill(4)}.mp3\"\n",
        "          chunk.export(output_filename, format=\"mp3\")\n",
        "\n",
        "    # If reduce_noise is True, apply noise reduction to all chunks\n",
        "    if reduce_noise:\n",
        "      reduce_noise_in_directory(output_folder)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown # Transcription. \n",
        "#@markdown Now we transcribe the audio-file to text using whisper. \n",
        "\n",
        "#@markdown You can choose the language in which you mainly spoke, and doing so improves results (adding more languages would be possible). If you specify a different language than the one you speak in, this can even serve as a translation tool. \n",
        "#@markdown If you use a lot of technical terminology, or something, it can help to paste a piece of text into the prompt-window, which is similar to your dictation.\n",
        "#@markdown There is also a reduce-noise function (as whisper is sensitive to background-noises), but I haven't quite gotten it to work yet.\n",
        "\n",
        "\n",
        "# Set the language for transcription\n",
        "language = 'en' #@param [\"en\", \"de\"] {allow-input: true}\n",
        "\n",
        "# Set whether to reduce noise\n",
        "reduce_noise= False #@param {type:\"boolean\"}\n",
        "\n",
        "# Set the prompt for transcription\n",
        "prompt = \"Email to Gareth\" #@param {type:\"string\"}\n",
        "\n",
        "# Set the input file and split it into chunks\n",
        "input_file = \"current_audio.mp3\"\n",
        "split_audio_file_into_chunks(input_file, output_folder='intermediate_chunks', chunk_length=300,reduce_noise=reduce_noise)\n",
        "\n",
        "# Transcribe each chunk and concatenate the transcriptions\n",
        "sub_transcripts = []\n",
        "for this_chunk in sorted(os.listdir('intermediate_chunks')):\n",
        "  audio_file= open('intermediate_chunks/'+this_chunk, \"rb\")\n",
        "  transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,language=language, prompt=prompt)\n",
        "  sub_transcripts.append(transcript.text)\n",
        "transcript = ' '.join(sub_transcripts)\n",
        "\n",
        "# Print the final transcription\n",
        "print(transcript)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Ms9IpJDpbR",
        "outputId": "766db7ee-7c5a-4838-a95d-4509a19927cc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey Gareth, so I saw you mentioned the dictation to writing workflow on Twitter and I thought I'd just quickly clean up my notebook that I made for that and if you would like to you can give it a little go and test everything and see what it works and I would be very grateful if you had time to do that and give me a little feedback, if there are any issues with it that I didn't anticipate Thanks and all the best, Max\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Importing the styles\n",
        "#@markdown This downloads some style-instructions I prepared from the Github repo. \n",
        "#@markdown Feel free to make you own and share them with me, so I can add them!\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/MNoichl/speech_to_text_with_whisper_to_GPT/main/style_library.json\n",
        "\n",
        "\n",
        "\n",
        "def load_json_file(file_path):\n",
        "    data = {}\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r') as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage\n",
        "file_path = 'style_library.json'\n",
        "loaded_style_dict = load_json_file(file_path)\n",
        "\n",
        "for x in loaded_style_dict.keys():\n",
        "  print(x) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OsD2hMNCYRDB",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975ef80d-6025-4734-d0d7-0503313837b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "haraway_epistemic\n",
            "howl_style\n",
            "koselleck_de\n",
            "lewis_david_plurality\n",
            "list_and_pettit\n",
            "max_noichl_emails_de\n",
            "max_noichl_emails_en\n",
            "max_to_do_list\n",
            "moby_dick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Fixing transcriptions using GPT\n",
        "\n",
        "\n",
        "style = \"max_emails_en\" #@param {type:\"string\"}\n",
        "if style in loaded_style_dict.keys():\n",
        "  style_instructions = loaded_style_dict[style]\n",
        "else: \n",
        "  style_instructions = style\n",
        "\n",
        "fixing_language = 'currently set language' #@param [\"currently set language\",\"en\", \"de\"] {allow-input: true}\n",
        "if 'currently set language' == fixing_language:\n",
        "  fixing_language = language \n",
        "\n",
        "OpenAi_model = \"gpt-4\" #@param [\"gpt-4\", \"3.5-turbo\"] {allow-input: true}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if fixing_language == 'en':\n",
        "  answer = openai.ChatCompletion.create(\n",
        "                    model=OpenAi_model,\n",
        "                    messages=[\n",
        "                          {\"role\": \"system\", \"content\": \"\"\"You are a perfect transcription program that is able to take faulty dictations and put them into a readable form, grammatically correct form without changing their content or changing their formulations. \"\"\"},\n",
        "                          {\"role\": \"user\", \"content\": (\"\"\"Transcribe this faulty dictation. Use all of the techniques in Writing Style A, which you are provided with below the dictation) to generate your result!\\n\"\"\" +\n",
        "                                                      \"\"\"<transcript start> \"\"\"+ transcript + \"\"\"<transcript end> \"\"\" + \"\"\"\\n\\n\"\"\"+\n",
        "                                                      \"\"\"Writing Style A: \"\"\"+\n",
        "                                                      style_instructions)},\n",
        "                      ]\n",
        "                  )\n",
        "  fixed_text = answer['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "elif fixing_language == 'de':\n",
        "  answer = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",  # 3.5-turbo\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": \"\"\"Du bist ein perfektes Transkriptionsprogramm, das in der Lage ist, fehlerhafte Diktate aufzunehmen und sie in eine lesbare, grammatikalisch korrekte Form zu bringen, ohne ihren Inhalt oder ihre Formulierungen zu ver√§ndern.\"\"\",\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": (\n",
        "                  \"\"\"Transkribiere dieses fehlerhafte Diktat. Verwende alle Techniken in Schreibstil A, die dir unter dem Diktat zur Verf√ºgung gestellt werden, um dein Ergebnis zu erzeugen!\\n\"\"\"\n",
        "                  + \"\"\"<transkript start> \"\"\"\n",
        "                  + transcript\n",
        "                  + \"\"\"<transkript ende> \"\"\"\n",
        "                  + \"\"\"\\n\\n\"\"\"\n",
        "                  + \"\"\"Schreibstil A: \"\"\"\n",
        "                  + style_instructions \n",
        "                  # + \"\"\"Transkribiere, ohne den Inhalt zu ver√§ndern\"\"\"\n",
        "              ),\n",
        "          },\n",
        "      ]\n",
        "  )\n",
        "  fixed_text = answer[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(fixed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2KAybASpfdH",
        "outputId": "8447d7fe-5013-4e90-cae3-068530fe2edd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Testing Dictation-to-Writing Workflow Notebook\n",
            "\n",
            "Dear Gareth,\n",
            "\n",
            "I hope this email finds you well. I recently came across your mention of the dictation-to-writing workflow on Twitter. I thought it would be a good idea to clean up the notebook I had created for that purpose. If you're interested, I would be grateful if you could give it a try and test everything to see how well it works.\n",
            "\n",
            "Your feedback would be invaluable to me, particularly if you encounter any issues that I may not have anticipated. Thank you in advance for your time and assistance.\n",
            "\n",
            "Best regards,\n",
            "Max\n"
          ]
        }
      ]
    }
  ]
}